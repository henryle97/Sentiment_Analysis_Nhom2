{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ck8MeA2nzn4q",
        "outputId": "310f21e9-a2ca-4646-a9a6-15811956b8b7"
      },
      "source": [
        "! pip install pyvi"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyvi in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.3.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.22.2.post1)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (0.9.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (0.8.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.19.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHUpOO1yzLfE"
      },
      "source": [
        "import pandas as pd\r\n",
        "import sklearn\r\n",
        "import pyvi"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9eRwojDzYgF",
        "outputId": "84f18f25-c7cf-4a87-89dd-e5c179bb3f70"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luS1X0tazjI-",
        "outputId": "5f4d7528-2dc7-4167-de78-eded1f109d1e"
      },
      "source": [
        "%cd '/content/drive/MyDrive/Vin/Basic Machine Learning/Project/Semantic-Analysis-Vietnamese/dataset'\r\n",
        "!ls"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Vin/Basic Machine Learning/Project/Semantic-Analysis-Vietnamese/dataset\n",
            "test_foody_processed.csv\t  train_foody_processed.csv\n",
            "train_foody_combine_tiki_72k.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "VwPISp2bzcdq",
        "outputId": "91d27e75-b38d-4e39-a81e-46c72ace8827"
      },
      "source": [
        "import pandas as pd\r\n",
        "df_train = pd.read_csv(\"train_foody_processed.csv\")\r\n",
        "df_test = pd.read_csv(\"test_foody_processed.csv\")\r\n",
        "df_train.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mua có mỗi bingsu thập_cẩm 45k mà mình f đợi h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>thứ 6 nào ta cùng quẩy vuvuzela ber club chung...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mình đi với nhóm tổng_cộng 4 người ăn chỉ có k...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nhân_viên phục_vụ không mấy tận_tình đồ ăn ra ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>vào đây thì hết bàn nhưng mình vẫn ngồi đợi bì...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment  label\n",
              "0  mua có mỗi bingsu thập_cẩm 45k mà mình f đợi h...      0\n",
              "1  thứ 6 nào ta cùng quẩy vuvuzela ber club chung...      0\n",
              "2  mình đi với nhóm tổng_cộng 4 người ăn chỉ có k...      0\n",
              "3  nhân_viên phục_vụ không mấy tận_tình đồ ăn ra ...      0\n",
              "4  vào đây thì hết bàn nhưng mình vẫn ngồi đợi bì...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "WHrdjCnzzhpS",
        "outputId": "4e0ef670-5975-478c-f2ee-d69a8b29f39c"
      },
      "source": [
        "df_train.iloc[1, 0]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'thứ 6 nào ta cùng quẩy vuvuzela ber club chung hệ_thống gogi house daruma kichi kichi nên giá cũng chưa 10 vat thanh_toán trước 20g hằng ngày được giảm 30 thức_ăn tính ra được giảm 20 cũng zui positive positive positive ngồi thư giãn cũng ok thức_ăn cũng ổn có mấy món nguyên_liệu bên ngoài không biết chỗ nào bán nên vô đây ăn cơ_mà gọi mấy món đó cũng không có hàng positive positive positive cháo bồ_câu hình chụp nguyên con bồ_câu mà tìm hoài chỉ thấy phao_câu không thấy đầu bồ_câu hỏi e nv e chạy hỏi nhà_bếp được trả_lời là 1 phần cháo được tính_toán 1 lượng thịt cố_định theo gram chứ không phải nguyên con chị ơi ps lần sau sẽ rủ trên 4 đứa đi quẩy để được tặng 10 ly bia mí được'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQonJoZY0Ykx",
        "outputId": "08ff74bc-01dd-4d36-f82b-286b98d36879"
      },
      "source": [
        "X_train_df, y_train = df_train['comment'], df_train['label']\r\n",
        "X_test, y_test = df_test['comment'], df_test['label']\r\n",
        "print(X_train_df.shape)\r\n",
        "print(X_test.shape)\r\n",
        "\r\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000,)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf_Jpgye1-D_"
      },
      "source": [
        "import numpy as np \r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,TfidfTransformer\r\n",
        "from scipy import sparse, io\r\n",
        "\r\n",
        "from sklearn.svm import SVC, LinearSVC\r\n",
        "from sklearn import metrics\r\n",
        "from scipy import io\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSm5IMZb-AWT",
        "outputId": "e66760e9-4cb2-42d1-b00a-39cb8d12993c"
      },
      "source": [
        "# Tfidf mặc định, LinearSVC mặc định\r\n",
        "tfidf_vectorizer = TfidfVectorizer()\r\n",
        "X_train = tfidf_vectorizer.fit_transform(X_train_df)\r\n",
        "vocab =  tfidf_vectorizer.get_feature_names()\r\n",
        "\r\n",
        "print(len(vocab))\r\n",
        "  \r\n",
        "clf = LinearSVC()\r\n",
        "\r\n",
        "clf.fit(X_train, y_train)\r\n",
        "\r\n",
        "y_pred = clf.predict(tfidf_vectorizer.transform(X_test))\r\n",
        "\r\n",
        "print(metrics.classification_report(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Accuracy: \", 100*metrics.accuracy_score(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Precision: \", 100*metrics.precision_score(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Recall (macro): \", 100*metrics.recall_score(y_test, y_pred, average='macro'))\r\n",
        "\r\n",
        "\r\n",
        "print(\"Recall(micro): \", 100*metrics.recall_score(y_test, y_pred, average='micro'))\r\n",
        "\r\n",
        "print(\"F1-scores(macro): \", 100*metrics.f1_score(y_test, y_pred, average='macro'))\r\n",
        "\r\n",
        "print(\"F1-scores(micro): \", 100*metrics.f1_score(y_test, y_pred, average='micro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35259\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.88      0.89      5000\n",
            "           1       0.89      0.90      0.89      5000\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "Accuracy:  89.0\n",
            "Precision:  88.53754940711462\n",
            "Recall (macro):  89.0\n",
            "Recall(micro):  89.0\n",
            "F1-scores(macro):  88.99960398574348\n",
            "F1-scores(micro):  89.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs3UA3JijsWK",
        "outputId": "25ed1abc-9772-4106-fa1f-0e98d6d49001"
      },
      "source": [
        "# Tfidf mặc định, SVC thay đổi tham số\r\n",
        "tfidf_vectorizer = TfidfVectorizer()\r\n",
        "X_train = tfidf_vectorizer.fit_transform(X_train_df)\r\n",
        "vocab =  tfidf_vectorizer.get_feature_names()\r\n",
        "\r\n",
        "print(len(vocab))\r\n",
        "C_values = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\r\n",
        "penalty=('l2', 'l1')\r\n",
        "param_grid = dict(C=C_values)\r\n",
        "scoring = 'neg_mean_squared_error'\r\n",
        "\r\n",
        "clf = LinearSVC()\r\n",
        "# clf = Pipeline([(('tfidf', TfidfTransformer()), ('clf', SVC())])\r\n",
        "\r\n",
        "gs_clf = GridSearchCV(clf, param_grid=param_grid, scoring=scoring, n_jobs=-1)\r\n",
        "gs_clf = gs_clf.fit(X_train, y_train)\r\n",
        "print(\"Best: %f using %s\" % (gs_clf.best_score_,gs_clf.best_params_))\r\n",
        "means = gs_clf.cv_results_['mean_test_score']\r\n",
        "stds = gs_clf.cv_results_['std_test_score']\r\n",
        "params = gs_clf.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "  print(\"%f (%f) with: %r\" % (mean, stdev, param))\r\n",
        "\r\n",
        "clf = LinearSVC(C = (gs_clf.best_params_['C']))\r\n",
        "\r\n",
        "clf.fit(X_train, y_train)\r\n",
        "\r\n",
        "y_pred = clf.predict(tfidf_vectorizer.transform(X_test))\r\n",
        "\r\n",
        "print(metrics.classification_report(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Accuracy: \", 100*metrics.accuracy_score(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Precision: \", 100*metrics.precision_score(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Recall (macro): \", 100*metrics.recall_score(y_test, y_pred, average='macro'))\r\n",
        "\r\n",
        "print(\"Recall(micro): \", 100*metrics.recall_score(y_test, y_pred, average='micro'))\r\n",
        "\r\n",
        "print(\"F1-scores(macro): \", 100*metrics.f1_score(y_test, y_pred, average='macro'))\r\n",
        "\r\n",
        "print(\"F1-scores(micro): \", 100*metrics.f1_score(y_test, y_pred, average='micro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35259\n",
            "Best: -0.111700 using {'C': 0.1}\n",
            "-0.160050 (0.005255) with: {'C': 0.001}\n",
            "-0.126875 (0.003230) with: {'C': 0.01}\n",
            "-0.111700 (0.003729) with: {'C': 0.1}\n",
            "-0.120825 (0.003070) with: {'C': 1.0}\n",
            "-0.154275 (0.002647) with: {'C': 10.0}\n",
            "-0.198450 (0.003855) with: {'C': 100.0}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.88      0.89      5000\n",
            "           1       0.89      0.91      0.90      5000\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "Accuracy:  89.41\n",
            "Precision:  88.52394916911047\n",
            "Recall (macro):  89.41\n",
            "Recall(micro):  89.41\n",
            "F1-scores(macro):  89.40859928725574\n",
            "F1-scores(micro):  89.41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI0UctINbN5o",
        "outputId": "3d66dd85-f951-4e4c-b8d5-58f94e5bd642"
      },
      "source": [
        "# tfidf tunning, LinearSVC tunning\r\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,5), max_df=0.5, min_df=5, smooth_idf=True, sublinear_tf=True, norm='l2', use_idf=False)\r\n",
        "X_train = tfidf_vectorizer.fit_transform(X_train_df)\r\n",
        "vocab =  tfidf_vectorizer.get_feature_names()\r\n",
        "\r\n",
        "print(len(vocab))\r\n",
        "C_values = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\r\n",
        "penalty=('l2', 'l1')\r\n",
        "param_grid = dict(C=C_values)\r\n",
        "scoring = 'neg_mean_squared_error'\r\n",
        "\r\n",
        "clf = LinearSVC()\r\n",
        "# clf = Pipeline([(('tfidf', TfidfTransformer()), ('clf', SVC())])\r\n",
        "\r\n",
        "gs_clf = GridSearchCV(clf, param_grid=param_grid, scoring=scoring, n_jobs=-1)\r\n",
        "gs_clf = gs_clf.fit(X_train, y_train)\r\n",
        "print(\"Best: %f using %s\" % (gs_clf.best_score_,gs_clf.best_params_))\r\n",
        "means = gs_clf.cv_results_['mean_test_score']\r\n",
        "stds = gs_clf.cv_results_['std_test_score']\r\n",
        "params = gs_clf.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "  print(\"%f (%f) with: %r\" % (mean, stdev, param))\r\n",
        "  \r\n",
        "\r\n",
        "clf = LinearSVC(C = gs_clf.best_params_['C'])\r\n",
        "\r\n",
        "clf.fit(X_train, y_train)\r\n",
        "\r\n",
        "y_pred = clf.predict(tfidf_vectorizer.transform(X_test))\r\n",
        "\r\n",
        "print(metrics.classification_report(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Accuracy: \", 100*metrics.accuracy_score(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Precision: \", 100*metrics.precision_score(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Recall (macro): \", 100*metrics.recall_score(y_test, y_pred, average='macro'))\r\n",
        "\r\n",
        "\r\n",
        "print(\"Recall(micro): \", 100*metrics.recall_score(y_test, y_pred, average='micro'))\r\n",
        "\r\n",
        "print(\"F1-scores(macro): \", 100*metrics.f1_score(y_test, y_pred, average='macro'))\r\n",
        "\r\n",
        "print(\"F1-scores(micro): \", 100*metrics.f1_score(y_test, y_pred, average='micro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "178138\n",
            "Best: -0.100650 using {'C': 1.0}\n",
            "-0.181250 (0.005367) with: {'C': 0.001}\n",
            "-0.133925 (0.002664) with: {'C': 0.01}\n",
            "-0.103825 (0.001501) with: {'C': 0.1}\n",
            "-0.100650 (0.002052) with: {'C': 1.0}\n",
            "-0.111800 (0.003546) with: {'C': 10.0}\n",
            "-0.115275 (0.003747) with: {'C': 100.0}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.90      0.90      5000\n",
            "           1       0.90      0.92      0.91      5000\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n",
            "Accuracy:  90.53999999999999\n",
            "Precision:  89.74509803921569\n",
            "Recall (macro):  90.53999999999999\n",
            "Recall(micro):  90.53999999999999\n",
            "F1-scores(macro):  90.53905390539055\n",
            "F1-scores(micro):  90.53999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyPpCYEi4YnB",
        "outputId": "d95967e8-31de-4813-c126-ced7a8433f52"
      },
      "source": [
        "# Bow mặc định, LinearSVC mặc định\r\n",
        "\r\n",
        "count_vectorizer = CountVectorizer()\r\n",
        "X_train = count_vectorizer.fit_transform(X_train_df)\r\n",
        "vocab =  count_vectorizer.get_feature_names()\r\n",
        "\r\n",
        "print(len(vocab))\r\n",
        "\r\n",
        "clf = LinearSVC()\r\n",
        "\r\n",
        "clf.fit(X_train, y_train)\r\n",
        "\r\n",
        "y_pred = clf.predict(count_vectorizer.transform(X_test))\r\n",
        "\r\n",
        "print(metrics.classification_report(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Accuracy: \", 100*metrics.accuracy_score(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Precision: \", 100*metrics.precision_score(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Recall (macro): \", 100*metrics.recall_score(y_test, y_pred, average='macro'))\r\n",
        "\r\n",
        "\r\n",
        "print(\"Recall(micro): \", 100*metrics.recall_score(y_test, y_pred, average='micro'))\r\n",
        "\r\n",
        "print(\"F1-scores(macro): \", 100*metrics.f1_score(y_test, y_pred, average='macro'))\r\n",
        "\r\n",
        "print(\"F1-scores(micro): \", 100*metrics.f1_score(y_test, y_pred, average='micro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35259\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86      5000\n",
            "           1       0.86      0.85      0.86      5000\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n",
            "Accuracy:  85.71\n",
            "Precision:  85.91832629249649\n",
            "Recall (macro):  85.71\n",
            "Recall(micro):  85.71\n",
            "F1-scores(macro):  85.70987982008928\n",
            "F1-scores(micro):  85.71000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8m33HPJctqf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d457a062-679a-4727-f9b7-518accb01815"
      },
      "source": [
        "# BoW mặc định, LinearSVC thay đổi các tham số\r\n",
        "count_vectorizer = CountVectorizer()\r\n",
        "X_train = count_vectorizer.fit_transform(X_train_df)\r\n",
        "vocab =  count_vectorizer.get_feature_names()\r\n",
        "print(len(vocab))\r\n",
        "C_values = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\r\n",
        "penalty=('l2', 'l1')\r\n",
        "param_grid = dict(C=C_values)\r\n",
        "scoring = 'neg_mean_squared_error'\r\n",
        "\r\n",
        "clf = LinearSVC()\r\n",
        "# clf = Pipeline([(('tfidf', TfidfTransformer()), ('clf', SVC())])\r\n",
        "\r\n",
        "gs_clf = GridSearchCV(clf, param_grid=param_grid, scoring=scoring, n_jobs=-1)\r\n",
        "gs_clf = gs_clf.fit(X_train, y_train)\r\n",
        "print(\"Best: %f using %s\" % (gs_clf.best_score_,gs_clf.best_params_))\r\n",
        "means = gs_clf.cv_results_['mean_test_score']\r\n",
        "stds = gs_clf.cv_results_['std_test_score']\r\n",
        "params = gs_clf.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "  print(\"%f (%f) with: %r\" % (mean, stdev, param))\r\n",
        "  \r\n",
        "clf = LinearSVC(C = gs_clf.best_params_['C'])\r\n",
        "\r\n",
        "clf.fit(X_train, y_train)\r\n",
        "y_pred = clf.predict(count_vectorizer.transform(X_test))\r\n",
        "\r\n",
        "print(metrics.classification_report(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Accuracy: \", 100*metrics.accuracy_score(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Precision: \", 100*metrics.precision_score(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Recall (macro): \", 100*metrics.recall_score(y_test, y_pred, average='macro'))\r\n",
        "\r\n",
        "\r\n",
        "print(\"Recall(micro): \", 100*metrics.recall_score(y_test, y_pred, average='micro'))\r\n",
        "\r\n",
        "print(\"F1-scores(macro): \", 100*metrics.f1_score(y_test, y_pred, average='macro'))\r\n",
        "\r\n",
        "print(\"F1-scores(micro): \", 100*metrics.f1_score(y_test, y_pred, average='micro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35259\n",
            "Best: -0.112950 using {'C': 0.01}\n",
            "-0.116650 (0.003357) with: {'C': 0.001}\n",
            "-0.112950 (0.001887) with: {'C': 0.01}\n",
            "-0.125775 (0.001417) with: {'C': 0.1}\n",
            "-0.153600 (0.002332) with: {'C': 1.0}\n",
            "-0.190375 (0.003362) with: {'C': 10.0}\n",
            "-0.205625 (0.003957) with: {'C': 100.0}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.89      0.89      5000\n",
            "           1       0.89      0.90      0.89      5000\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "Accuracy:  89.34\n",
            "Precision:  88.75098502758078\n",
            "Recall (macro):  89.34\n",
            "Recall(micro):  89.34\n",
            "F1-scores(macro):  89.33938424283386\n",
            "F1-scores(micro):  89.34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIzofm8JpQd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a09c7b08-9c2a-4c1f-8dd3-c0c4dc82aabc"
      },
      "source": [
        "# BoW thay đổi các tham số, LinearSVC thay đổi các tham số\r\n",
        "count_vectorizer = CountVectorizer(ngram_range=(1,5), max_df=0.5, min_df=5)\r\n",
        "X_train = count_vectorizer.fit_transform(X_train_df)\r\n",
        "vocab =  count_vectorizer.get_feature_names()\r\n",
        "print(len(vocab))\r\n",
        "C_values = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\r\n",
        "penalty=('l2', 'l1')\r\n",
        "param_grid = dict(C=C_values)\r\n",
        "scoring = 'neg_mean_squared_error'\r\n",
        "\r\n",
        "clf = LinearSVC()\r\n",
        "# clf = Pipeline([(('tfidf', TfidfTransformer()), ('clf', SVC())])\r\n",
        "\r\n",
        "gs_clf = GridSearchCV(clf, param_grid=param_grid, scoring=scoring, n_jobs=-1)\r\n",
        "gs_clf = gs_clf.fit(X_train, y_train)\r\n",
        "print(\"Best: %f using %s\" % (gs_clf.best_score_,gs_clf.best_params_))\r\n",
        "means = gs_clf.cv_results_['mean_test_score']\r\n",
        "stds = gs_clf.cv_results_['std_test_score']\r\n",
        "params = gs_clf.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "  print(\"%f (%f) with: %r\" % (mean, stdev, param))\r\n",
        "\r\n",
        "clf = LinearSVC(C = gs_clf.best_params_['C'])\r\n",
        "\r\n",
        "clf.fit(X_train, y_train)\r\n",
        "\r\n",
        "y_pred = clf.predict(count_vectorizer.transform(X_test))\r\n",
        "\r\n",
        "print(metrics.classification_report(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Accuracy: \", 100*metrics.accuracy_score(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Precision: \", 100*metrics.precision_score(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Recall (macro): \", 100*metrics.recall_score(y_test, y_pred, average='macro'))\r\n",
        "\r\n",
        "\r\n",
        "print(\"Recall(micro): \", 100*metrics.recall_score(y_test, y_pred, average='micro'))\r\n",
        "\r\n",
        "print(\"F1-scores(macro): \", 100*metrics.f1_score(y_test, y_pred, average='macro'))\r\n",
        "\r\n",
        "print(\"F1-scores(micro): \", 100*metrics.f1_score(y_test, y_pred, average='micro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "178138\n",
            "Best: -0.103375 using {'C': 0.01}\n",
            "-0.104000 (0.002420) with: {'C': 0.001}\n",
            "-0.103375 (0.002764) with: {'C': 0.01}\n",
            "-0.116725 (0.004426) with: {'C': 0.1}\n",
            "-0.123525 (0.004396) with: {'C': 1.0}\n",
            "-0.125850 (0.004303) with: {'C': 10.0}\n",
            "-0.128925 (0.005187) with: {'C': 100.0}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.90      0.90      5000\n",
            "           1       0.90      0.91      0.91      5000\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.90      0.90      0.90     10000\n",
            "\n",
            "Accuracy:  90.47\n",
            "Precision:  89.80916781428292\n",
            "Recall (macro):  90.47\n",
            "Recall(micro):  90.47\n",
            "F1-scores(macro):  90.46934343306911\n",
            "F1-scores(micro):  90.47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfn1Z7veE-dr",
        "outputId": "4fe03b5d-0e26-4144-d7d4-f21dccb6bb1f"
      },
      "source": [
        "# tfidf tunning, LinearSVC tunning\r\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,5), max_df=0.5, min_df=5, smooth_idf=True, sublinear_tf=True, norm='l2', use_idf=False)\r\n",
        "X_train = tfidf_vectorizer.fit_transform(X_train_df)\r\n",
        "vocab =  tfidf_vectorizer.get_feature_names()\r\n",
        "\r\n",
        "print(len(vocab))\r\n",
        "C_values = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\r\n",
        "penalty=('l2', 'l1')\r\n",
        "tol = [0.000001, 0.00001, 0.0001, 0.001]\r\n",
        "param_grid = dict(C=C_values, tol=tol)\r\n",
        "scoring = 'neg_mean_squared_error'\r\n",
        "\r\n",
        "clf = LinearSVC()\r\n",
        "# clf = Pipeline([(('tfidf', TfidfTransformer()), ('clf', SVC())])\r\n",
        "\r\n",
        "gs_clf = GridSearchCV(clf, param_grid=param_grid, scoring=scoring, n_jobs=-1)\r\n",
        "gs_clf = gs_clf.fit(X_train, y_train)\r\n",
        "print(\"Best: %f using %s\" % (gs_clf.best_score_,gs_clf.best_params_))\r\n",
        "means = gs_clf.cv_results_['mean_test_score']\r\n",
        "stds = gs_clf.cv_results_['std_test_score']\r\n",
        "params = gs_clf.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "  print(\"%f (%f) with: %r\" % (mean, stdev, param))\r\n",
        "  \r\n",
        "\r\n",
        "clf = LinearSVC(C = gs_clf.best_params_['C'])\r\n",
        "\r\n",
        "clf.fit(X_train, y_train)\r\n",
        "\r\n",
        "y_pred = clf.predict(tfidf_vectorizer.transform(X_test))\r\n",
        "\r\n",
        "print(metrics.classification_report(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Accuracy: \", 100*metrics.accuracy_score(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Precision: \", 100*metrics.precision_score(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Recall (macro): \", 100*metrics.recall_score(y_test, y_pred, average='macro'))\r\n",
        "\r\n",
        "\r\n",
        "print(\"Recall(micro): \", 100*metrics.recall_score(y_test, y_pred, average='micro'))\r\n",
        "\r\n",
        "print(\"F1-scores(macro): \", 100*metrics.f1_score(y_test, y_pred, average='macro'))\r\n",
        "\r\n",
        "print(\"F1-scores(micro): \", 100*metrics.f1_score(y_test, y_pred, average='micro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "178138\n",
            "Best: -0.100650 using {'C': 1.0, 'tol': 1e-06}\n",
            "-0.181250 (0.005367) with: {'C': 0.001, 'tol': 1e-06}\n",
            "-0.181250 (0.005367) with: {'C': 0.001, 'tol': 1e-05}\n",
            "-0.181250 (0.005367) with: {'C': 0.001, 'tol': 0.0001}\n",
            "-0.181250 (0.005367) with: {'C': 0.001, 'tol': 0.001}\n",
            "-0.133925 (0.002664) with: {'C': 0.01, 'tol': 1e-06}\n",
            "-0.133925 (0.002664) with: {'C': 0.01, 'tol': 1e-05}\n",
            "-0.133925 (0.002664) with: {'C': 0.01, 'tol': 0.0001}\n",
            "-0.133925 (0.002664) with: {'C': 0.01, 'tol': 0.001}\n",
            "-0.103825 (0.001501) with: {'C': 0.1, 'tol': 1e-06}\n",
            "-0.103825 (0.001501) with: {'C': 0.1, 'tol': 1e-05}\n",
            "-0.103825 (0.001501) with: {'C': 0.1, 'tol': 0.0001}\n",
            "-0.103825 (0.001501) with: {'C': 0.1, 'tol': 0.001}\n",
            "-0.100650 (0.002052) with: {'C': 1.0, 'tol': 1e-06}\n",
            "-0.100650 (0.002052) with: {'C': 1.0, 'tol': 1e-05}\n",
            "-0.100650 (0.002052) with: {'C': 1.0, 'tol': 0.0001}\n",
            "-0.100650 (0.002052) with: {'C': 1.0, 'tol': 0.001}\n",
            "-0.111800 (0.003546) with: {'C': 10.0, 'tol': 1e-06}\n",
            "-0.111800 (0.003546) with: {'C': 10.0, 'tol': 1e-05}\n",
            "-0.111800 (0.003546) with: {'C': 10.0, 'tol': 0.0001}\n",
            "-0.111800 (0.003546) with: {'C': 10.0, 'tol': 0.001}\n",
            "-0.115275 (0.003747) with: {'C': 100.0, 'tol': 1e-06}\n",
            "-0.115250 (0.003757) with: {'C': 100.0, 'tol': 1e-05}\n",
            "-0.115275 (0.003747) with: {'C': 100.0, 'tol': 0.0001}\n",
            "-0.115275 (0.003747) with: {'C': 100.0, 'tol': 0.001}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.90      0.90      5000\n",
            "           1       0.90      0.92      0.91      5000\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n",
            "Accuracy:  90.53999999999999\n",
            "Precision:  89.74509803921569\n",
            "Recall (macro):  90.53999999999999\n",
            "Recall(micro):  90.53999999999999\n",
            "F1-scores(macro):  90.53905390539055\n",
            "F1-scores(micro):  90.53999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCOh4zViCaxJ",
        "outputId": "53b5ff05-1123-495b-96e5-670487cf04df"
      },
      "source": [
        "# tfidf tunning, LinearSVC tunning\r\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,5), max_df=0.5, min_df=5, smooth_idf=True, sublinear_tf=True, norm='l2', use_idf=True)\r\n",
        "X_train = tfidf_vectorizer.fit_transform(X_train_df)\r\n",
        "vocab =  tfidf_vectorizer.get_feature_names()\r\n",
        "\r\n",
        "print(len(vocab))\r\n",
        "C_values = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\r\n",
        "penalty=('l2', 'l1')\r\n",
        "tol = [0.000001, 0.00001, 0.0001, 0.001]\r\n",
        "param_grid = dict(C=C_values, tol=tol)\r\n",
        "scoring = 'neg_mean_squared_error'\r\n",
        "\r\n",
        "clf = LinearSVC()\r\n",
        "# clf = Pipeline([(('tfidf', TfidfTransformer()), ('clf', SVC())])\r\n",
        "\r\n",
        "gs_clf = GridSearchCV(clf, param_grid=param_grid, scoring=scoring, n_jobs=-1)\r\n",
        "gs_clf = gs_clf.fit(X_train, y_train)\r\n",
        "print(\"Best: %f using %s\" % (gs_clf.best_score_,gs_clf.best_params_))\r\n",
        "means = gs_clf.cv_results_['mean_test_score']\r\n",
        "stds = gs_clf.cv_results_['std_test_score']\r\n",
        "params = gs_clf.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "  print(\"%f (%f) with: %r\" % (mean, stdev, param))\r\n",
        "  \r\n",
        "\r\n",
        "clf = LinearSVC(C = gs_clf.best_params_['C'])\r\n",
        "\r\n",
        "clf.fit(X_train, y_train)\r\n",
        "\r\n",
        "y_pred = clf.predict(tfidf_vectorizer.transform(X_test))\r\n",
        "\r\n",
        "print(metrics.classification_report(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Accuracy: \", 100*metrics.accuracy_score(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Precision: \", 100*metrics.precision_score(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Recall (macro): \", 100*metrics.recall_score(y_test, y_pred, average='macro'))\r\n",
        "\r\n",
        "\r\n",
        "print(\"Recall(micro): \", 100*metrics.recall_score(y_test, y_pred, average='micro'))\r\n",
        "\r\n",
        "print(\"F1-scores(macro): \", 100*metrics.f1_score(y_test, y_pred, average='macro'))\r\n",
        "\r\n",
        "print(\"F1-scores(micro): \", 100*metrics.f1_score(y_test, y_pred, average='micro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "178138\n",
            "Best: -0.099075 using {'C': 0.1, 'tol': 1e-06}\n",
            "-0.145300 (0.004831) with: {'C': 0.001, 'tol': 1e-06}\n",
            "-0.145300 (0.004831) with: {'C': 0.001, 'tol': 1e-05}\n",
            "-0.145300 (0.004831) with: {'C': 0.001, 'tol': 0.0001}\n",
            "-0.145300 (0.004831) with: {'C': 0.001, 'tol': 0.001}\n",
            "-0.121525 (0.003805) with: {'C': 0.01, 'tol': 1e-06}\n",
            "-0.121525 (0.003805) with: {'C': 0.01, 'tol': 1e-05}\n",
            "-0.121525 (0.003805) with: {'C': 0.01, 'tol': 0.0001}\n",
            "-0.121525 (0.003805) with: {'C': 0.01, 'tol': 0.001}\n",
            "-0.099075 (0.001117) with: {'C': 0.1, 'tol': 1e-06}\n",
            "-0.099075 (0.001117) with: {'C': 0.1, 'tol': 1e-05}\n",
            "-0.099075 (0.001117) with: {'C': 0.1, 'tol': 0.0001}\n",
            "-0.099075 (0.001117) with: {'C': 0.1, 'tol': 0.001}\n",
            "-0.099600 (0.002522) with: {'C': 1.0, 'tol': 1e-06}\n",
            "-0.099600 (0.002522) with: {'C': 1.0, 'tol': 1e-05}\n",
            "-0.099600 (0.002522) with: {'C': 1.0, 'tol': 0.0001}\n",
            "-0.099600 (0.002522) with: {'C': 1.0, 'tol': 0.001}\n",
            "-0.108475 (0.003741) with: {'C': 10.0, 'tol': 1e-06}\n",
            "-0.108475 (0.003741) with: {'C': 10.0, 'tol': 1e-05}\n",
            "-0.108475 (0.003741) with: {'C': 10.0, 'tol': 0.0001}\n",
            "-0.108475 (0.003741) with: {'C': 10.0, 'tol': 0.001}\n",
            "-0.111150 (0.003347) with: {'C': 100.0, 'tol': 1e-06}\n",
            "-0.111150 (0.003347) with: {'C': 100.0, 'tol': 1e-05}\n",
            "-0.111150 (0.003347) with: {'C': 100.0, 'tol': 0.0001}\n",
            "-0.111150 (0.003347) with: {'C': 100.0, 'tol': 0.001}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.89      0.90      5000\n",
            "           1       0.89      0.92      0.91      5000\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n",
            "Accuracy:  90.66\n",
            "Precision:  89.30781129156999\n",
            "Recall (macro):  90.66\n",
            "Recall(micro):  90.66\n",
            "F1-scores(macro):  90.6572360367091\n",
            "F1-scores(micro):  90.66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS2brCWAL4De",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08cd805c-bcee-4663-9b95-48b932622da3"
      },
      "source": [
        "# Tfidf tunning, LinearSVC mặc định\r\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,5), max_df=0.5, min_df=5, smooth_idf=True, sublinear_tf=True, norm='l2', use_idf=True)\r\n",
        "X_train = tfidf_vectorizer.fit_transform(X_train_df)\r\n",
        "vocab =  tfidf_vectorizer.get_feature_names()\r\n",
        "\r\n",
        "print(len(vocab))\r\n",
        "  \r\n",
        "clf = LinearSVC()\r\n",
        "\r\n",
        "clf.fit(X_train, y_train)\r\n",
        "\r\n",
        "y_pred = clf.predict(tfidf_vectorizer.transform(X_test))\r\n",
        "\r\n",
        "print(metrics.classification_report(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Accuracy: \", 100*metrics.accuracy_score(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Precision: \", 100*metrics.precision_score(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Recall (macro): \", 100*metrics.recall_score(y_test, y_pred, average='macro'))\r\n",
        "\r\n",
        "\r\n",
        "print(\"Recall(micro): \", 100*metrics.recall_score(y_test, y_pred, average='micro'))\r\n",
        "\r\n",
        "print(\"F1-scores(macro): \", 100*metrics.f1_score(y_test, y_pred, average='macro'))\r\n",
        "\r\n",
        "print(\"F1-scores(micro): \", 100*metrics.f1_score(y_test, y_pred, average='micro'))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "178138\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.90      0.91      5000\n",
            "           1       0.90      0.92      0.91      5000\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n",
            "Accuracy:  90.63\n",
            "Precision:  89.88808168073827\n",
            "Recall (macro):  90.63\n",
            "Recall(micro):  90.63\n",
            "F1-scores(macro):  90.62918951860146\n",
            "F1-scores(micro):  90.63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTMEWcOZhpQn",
        "outputId": "62b73a0d-fe67-47ea-c9a8-4e5702dd5862"
      },
      "source": [
        "# Bow Tunning, LinearSVC mặc định\r\n",
        "count_vectorizer = CountVectorizer(ngram_range=(1,5), max_df=0.5, min_df=5)\r\n",
        "X_train = count_vectorizer.fit_transform(X_train_df)\r\n",
        "vocab =  count_vectorizer.get_feature_names()\r\n",
        "print(len(vocab))\r\n",
        "\r\n",
        "clf = LinearSVC()\r\n",
        "\r\n",
        "clf.fit(X_train, y_train)\r\n",
        "\r\n",
        "y_pred = clf.predict(count_vectorizer.transform(X_test))\r\n",
        "\r\n",
        "print(metrics.classification_report(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Accuracy: \", 100*metrics.accuracy_score(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Precision: \", 100*metrics.precision_score(y_test, y_pred))\r\n",
        "\r\n",
        "print(\"Recall (macro): \", 100*metrics.recall_score(y_test, y_pred, average='macro'))\r\n",
        "\r\n",
        "\r\n",
        "print(\"Recall(micro): \", 100*metrics.recall_score(y_test, y_pred, average='micro'))\r\n",
        "\r\n",
        "print(\"F1-scores(macro): \", 100*metrics.f1_score(y_test, y_pred, average='macro'))\r\n",
        "\r\n",
        "print(\"F1-scores(micro): \", 100*metrics.f1_score(y_test, y_pred, average='micro'))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "178138\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88      5000\n",
            "           1       0.88      0.88      0.88      5000\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "Accuracy:  88.29\n",
            "Precision:  88.42063014248444\n",
            "Recall (macro):  88.29\n",
            "Recall(micro):  88.29\n",
            "F1-scores(macro):  88.2899661580022\n",
            "F1-scores(micro):  88.29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxeeKhFyiLeb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}